'use client';

/**
 * Apple é£æ ¼éŸ³é¢‘æ³¢å½¢å¯è§†åŒ–ç»„ä»¶ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
 * ä¿®å¤ï¼šæ¯æ¬¡å½•éŸ³åˆ›å»ºæ–°çš„AudioContextï¼Œæ­£ç¡®æ¸…ç†èµ„æº
 */

import React, { useRef, useEffect, useState } from 'react';
import { cn } from '@/lib/utils';

interface AppleStyleWaveformProps {
  stream: MediaStream | null;
  isRecording: boolean;
  variant?: 'default' | 'compact';
  className?: string;
}

export function AppleStyleWaveform({ 
  stream,
  isRecording,
  variant = 'default',
  className 
}: AppleStyleWaveformProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationFrameRef = useRef<number | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const [isSupported, setIsSupported] = useState(false);

  // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
  useEffect(() => {
    const AudioContextClass = window.AudioContext || (window as typeof window & { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
    setIsSupported(!!AudioContextClass && !!stream);
  }, [stream]);

  useEffect(() => {
    if (!isSupported || !canvasRef.current || !stream || !isRecording) {
      return;
    }

    const canvas = canvasRef.current;
    const canvasCtx = canvas.getContext('2d');
    if (!canvasCtx) return;

    // è®¾ç½® Canvas å°ºå¯¸ï¼ˆè€ƒè™‘è®¾å¤‡åƒç´ æ¯”ï¼‰
    const dpr = window.devicePixelRatio || 1;
    const rect = canvas.getBoundingClientRect();
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    canvasCtx.scale(dpr, dpr);

    // ä¿å­˜canvaså¼•ç”¨ç”¨äºæ¸…ç†
    const canvasForCleanup = canvas;

    console.log('ğŸ¨ åˆå§‹åŒ–æ³¢å½¢å¯è§†åŒ–...');

    try {
      // â­ æ¯æ¬¡å½•éŸ³åˆ›å»ºæ–°çš„AudioContextï¼Œé¿å…çŠ¶æ€æ··ä¹±
      const AudioContextClass = window.AudioContext || (window as typeof window & { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
      const audioContext = new AudioContextClass();
      audioContextRef.current = audioContext;
      
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048; // æ›´é«˜çš„é‡‡æ ·ç‡ï¼Œæ›´æµç•…
      analyser.smoothingTimeConstant = 0.85; // æ›´é«˜çš„å¹³æ»‘åº¦
      analyserRef.current = analyser;

      const source = audioContext.createMediaStreamSource(stream);
      sourceRef.current = source;
      source.connect(analyser);

      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      console.log('âœ… æ³¢å½¢å¯è§†åŒ–åˆå§‹åŒ–æˆåŠŸ');

      // ç»˜åˆ¶å‡½æ•°
      const draw = () => {
        if (!analyserRef.current || !canvasCtx) return;

        animationFrameRef.current = requestAnimationFrame(draw);

        analyserRef.current.getByteTimeDomainData(dataArray);

        // æ¸…ç©ºç”»å¸ƒ
        canvasCtx.clearRect(0, 0, rect.width, rect.height);

        // è®¾ç½®çº¿æ¡æ ·å¼
        canvasCtx.lineWidth = 2.5;
        canvasCtx.lineCap = 'round';
        canvasCtx.lineJoin = 'round';
        
        // åˆ›å»ºæ¸å˜è‰²
        const gradient = canvasCtx.createLinearGradient(0, 0, rect.width, 0);
        if (variant === 'compact') {
          gradient.addColorStop(0, '#ef4444');
          gradient.addColorStop(0.5, '#f97316');
          gradient.addColorStop(1, '#ef4444');
        } else {
          gradient.addColorStop(0, '#a855f7');
          gradient.addColorStop(0.5, '#ec4899');
          gradient.addColorStop(1, '#a855f7');
        }
        canvasCtx.strokeStyle = gradient;

        // å¼€å§‹ç»˜åˆ¶è·¯å¾„
        canvasCtx.beginPath();

        const sliceWidth = rect.width / bufferLength;
        let x = 0;

        // ä½¿ç”¨äºŒæ¬¡è´å¡å°”æ›²çº¿ç»˜åˆ¶å¹³æ»‘æ³¢å½¢
        const points: { x: number; y: number }[] = [];
        
        for (let i = 0; i < bufferLength; i++) {
          const v = dataArray[i] / 128.0;
          const y = (v * rect.height) / 2;
          points.push({ x, y });
          x += sliceWidth;
        }

        // ç»˜åˆ¶å¹³æ»‘æ›²çº¿
        if (points.length > 0) {
          canvasCtx.moveTo(points[0].x, points[0].y);

          for (let i = 1; i < points.length - 1; i++) {
            const xc = (points[i].x + points[i + 1].x) / 2;
            const yc = (points[i].y + points[i + 1].y) / 2;
            canvasCtx.quadraticCurveTo(points[i].x, points[i].y, xc, yc);
          }

          // æœ€åä¸€ä¸ªç‚¹
          if (points.length > 1) {
            canvasCtx.quadraticCurveTo(
              points[points.length - 1].x,
              points[points.length - 1].y,
              points[points.length - 1].x,
              points[points.length - 1].y
            );
          }
        }

        canvasCtx.stroke();

        // æ·»åŠ å¾®å¦™çš„è¾‰å…‰æ•ˆæœ
        if (variant === 'compact') {
          canvasCtx.shadowBlur = 8;
          canvasCtx.shadowColor = 'rgba(239, 68, 68, 0.3)';
        } else {
          canvasCtx.shadowBlur = 10;
          canvasCtx.shadowColor = 'rgba(168, 85, 247, 0.3)';
        }
        canvasCtx.stroke();
      };

      draw();
    } catch (error) {
      console.error('âŒ æ³¢å½¢å¯è§†åŒ–åˆå§‹åŒ–å¤±è´¥:', error);
    }

    // â­ æ¸…ç†å‡½æ•° - ç¡®ä¿æ¯æ¬¡éƒ½æ­£ç¡®æ¸…ç†
    return () => {
      console.log('ğŸ§¹ æ¸…ç†æ³¢å½¢å¯è§†åŒ–èµ„æº...');
      
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
      
      if (sourceRef.current) {
        try {
          sourceRef.current.disconnect();
          sourceRef.current = null;
          console.log('âœ… AudioSource å·²æ–­å¼€');
        } catch (e) {
          console.warn('âš ï¸ AudioSource æ–­å¼€å¤±è´¥:', e);
        }
      }
      
      if (audioContextRef.current) {
        try {
          audioContextRef.current.close();
          audioContextRef.current = null;
          console.log('âœ… AudioContext å·²å…³é—­');
        } catch (e) {
          console.warn('âš ï¸ AudioContext å…³é—­å¤±è´¥:', e);
        }
      }
      
      if (canvasForCleanup && canvasForCleanup.getContext('2d')) {
        const ctx = canvasForCleanup.getContext('2d');
        if (ctx) {
          ctx.clearRect(0, 0, canvasForCleanup.width, canvasForCleanup.height);
        }
      }
      
      console.log('âœ… æ³¢å½¢å¯è§†åŒ–èµ„æºæ¸…ç†å®Œæˆ');
    };
  }, [isSupported, stream, isRecording, variant]);

  if (!isSupported || !stream || !isRecording) {
    return null;
  }

  const height = variant === 'compact' ? 'h-16' : 'h-24';

  return (
    <div 
      className={cn(
        "relative w-full overflow-hidden rounded-lg backdrop-blur-sm",
        variant === 'compact' 
          ? 'bg-gradient-to-r from-red-500/10 via-orange-500/10 to-red-500/10 border border-red-500/20' 
          : 'bg-gradient-to-r from-purple-500/10 via-pink-500/10 to-purple-500/10 border border-purple-500/20',
        height,
        className
      )}
    >
      <canvas
        ref={canvasRef}
        className="w-full h-full"
        style={{ display: 'block' }}
      />
    </div>
  );
}

